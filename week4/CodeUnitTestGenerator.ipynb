{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# Code Generator\n",
    "\n",
    "The requirement: use an Open Source model to generate high performance C++ code from Python code\n",
    "\n",
    "To replicate this, you'll need to set up a HuggingFace endpoint as I do in the video. It's simple to do, and it's quite satisfying to see the results!\n",
    "\n",
    "It's also an important part of your learning; this is the first example of deploying an open source model to be behind an API. We'll return to this in Week 8, but this should plant a seed in your mind for what's involved in moving open source models into production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that helps to create unit tests for python code. \"\n",
    "system_message += \"Respond only with unit tests for the given python code that will exersize all test cases.\"\n",
    "system_message += \"Make nessecary comments and document as needed to help deveopers undersand what the unit tests are doing and the use cases that are being tested.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(python):\n",
    "    user_prompt = \"Create Unit test for the following python code that will cover all test cases.\"\n",
    "    user_prompt += \"Respond only with Python code. \"\n",
    "    user_prompt += python\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e1ba8c-5b05-4726-a9f3-8d8c6257350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file called optimized.cpp\n",
    "\n",
    "def write_output(cpp, filename):\n",
    "    code = cpp.replace(\"```cpp\",\"\").replace(\"```\",\"\")\n",
    "    with open(f\"{filename}.py\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unit_tests_gpt(python, save_file_name):    \n",
    "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        print(fragment, end='', flush=True)\n",
    "    write_output(reply, save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cbb778-fa57-43de-b04b-ed523f396c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105db6f9-343c-491d-8e44-3a5328b81719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import unittest\n",
      "\n",
      "# Import the function to be tested\n",
      "from your_module import calculate  # Assuming the main code is in 'your_module.py'\n",
      "\n",
      "class TestCalculateFunction(unittest.TestCase):\n",
      "    \n",
      "    def test_zero_iterations(self):\n",
      "        # Test case when iterations are zero\n",
      "        self.assertEqual(calculate(0, 4, 1), 1.0)\n",
      "\n",
      "    def test_single_iteration(self):\n",
      "        # Test single iteration\n",
      "        result = calculate(1, 4, 1)\n",
      "        self.assertAlmostEqual(result, 1 + (1/3) - (1/5), places=12)\n",
      "\n",
      "    def test_multiple_iterations(self):\n",
      "        # Test some custom value for the iterations\n",
      "        result = calculate(2, 4, 1)\n",
      "        # The expected result is calculated manually or using a reliable method\n",
      "        expected_result = 1 + (1/3) - (1/5) + (1/7) - (1/9)\n",
      "        self.assertAlmostEqual(result, expected_result, places=12)\n",
      "\n",
      "    def test_negative_param1(self):\n",
      "        # Test case when param1 is negative\n",
      "        result = calculate(1, -4, 1)\n",
      "        self.assertAlmostEqual(result, calculate(1, 4, -1), places=12)\n",
      "\n",
      "    def test_negative_param2(self):\n",
      "        # Test case when param2 is negative\n",
      "        result = calculate(1, 4, -1)\n",
      "        self.assertAlmostEqual(result, calculate(1, -4, 1), places=12)\n",
      "\n",
      "    def test_large_param1_and_param2(self):\n",
      "        # Edge test case for large values of param1 and param2\n",
      "        result = calculate(10, 10**6, 10**5)\n",
      "        # Without known expected output, we only check it runs without errors or performance issues\n",
      "        self.assertIsInstance(result, float)  # Ensure the result is a float\n",
      "\n",
      "    def test_large_iterations(self):\n",
      "        # Edge test case for maximum possible iterations\n",
      "        result = calculate(1000, 4, 1)\n",
      "        self.assertIsInstance(result, float)  # Ensure the result is a float\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "Please make sure to change `'your_module'` to the actual module name where the function `calculate` is defined. This test suite covers edge cases, normal cases, and checks for functionality with various parameter inputs."
     ]
    }
   ],
   "source": [
    "create_unit_tests_gpt(pi, 'test_calculate_pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3b497b3-f569-420e-b92e-fb0f49957ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"# Be careful to support large number sizes\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b3d073-88a2-40b2-831c-6f0c345c256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import unittest\n",
      "\n",
      "class TestLcgAndSubarraySum(unittest.TestCase):\n",
      "    def test_lcg(self):\n",
      "        # Test the LCG generator with a known seed\n",
      "        gen = lcg(12345)\n",
      "        self.assertEqual(next(gen), 87628868)\n",
      "        self.assertEqual(next(gen), 71072467)\n",
      "        self.assertEqual(next(gen), 2332836379)\n",
      "        self.assertEqual(next(gen), 2540403940)\n",
      "\n",
      "    def test_max_subarray_sum_small_range(self):\n",
      "        # Test with a small range of random numbers\n",
      "        n = 5\n",
      "        seed = 1\n",
      "        min_val = -2\n",
      "        max_val = 2\n",
      "        # Generating the array expected from (min_val, max_val)\n",
      "        # The possible range is limited and you might manually calculate expected result\n",
      "        self.assertEqual(max_subarray_sum(n, seed, min_val, max_val), 4) # this should be calculated based on LCG\n",
      "\n",
      "    def test_max_subarray_sum_large_random_numbers(self):\n",
      "        # Test max subarray sum with a large n to ensure handling of larger sizes\n",
      "        n = 10000\n",
      "        seed = 42\n",
      "        min_val = -1000\n",
      "        max_val = 1000\n",
      "        result = max_subarray_sum(n, seed, min_val, max_val)\n",
      "        self.assertTrue(isinstance(result, int))\n",
      "        # No assertion because it's hard to predict output, but checks performance\n",
      "\n",
      "    def test_total_max_subarray_sum(self):\n",
      "        # Test total max subarray sum calculation across 20 iterations\n",
      "        n = 50\n",
      "        initial_seed = 42\n",
      "        min_val = -10\n",
      "        max_val = 10\n",
      "        result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
      "        self.assertTrue(isinstance(result, int))\n",
      "\n",
      "    def test_edge_case_all_negative(self):\n",
      "        # Test where min_val and max_val are both negative, checks how negative sums are handled\n",
      "        n = 10\n",
      "        seed = 5\n",
      "        min_val = -5\n",
      "        max_val = -1\n",
      "        result = max_subarray_sum(n, seed, min_val, max_val)\n",
      "        self.assertTrue(result <= 0)  # Maximum sum can be zero or negative\n",
      "\n",
      "    def test_edge_case_single_value(self):\n",
      "        # Test where there's only one value (edge case for smallest n)\n",
      "        n = 1\n",
      "        seed = 99\n",
      "        min_val = 0\n",
      "        max_val = 0\n",
      "        result = max_subarray_sum(n, seed, min_val, max_val)\n",
      "        self.assertEqual(result, 0)  # Only one number in range is 0\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "This unit test suite covers various scenarios in the provided code:\n",
      "\n",
      "1. **LCG Functionality**: Tests `lcg()` to ensure it generates numbers as expected with a known seed.\n",
      "2. **Max Subarray Sum with Small Range**: Validates the `max_subarray_sum()` function to calculate the maximum subarray sum given a small range of numbers.\n",
      "3. **Handling Large Numbers**: Ensures `max_subarray_sum()` efficiently handles large `n` sizes for performance without explicitly checking the result due to its unpredictability.\n",
      "4. **20 Runs of Max Subarray Sum**: Checks if `total_max_subarray_sum()` correctly handles generating a sum across 20 subarray sum iterations.\n",
      "5. **Edge Case - All Negative**: Ensures negative ranges are handled correctly by `max_subarray_sum()`.\n",
      "6. **Edge Case - Single Value**: Validates that even with `n=1`, the function behaves expectedly when generating numbers out of a range of single possible values.\n",
      "\n",
      "These tests aim to ensure the code behaves correctly under typical scenarios and edge cases."
     ]
    }
   ],
   "source": [
    "create_unit_tests_gpt(python_hard, 'test_total_max_subarray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0be9f47d-5213-4700-b0e2-d444c7c738c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(python):    \n",
    "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply.replace('```cpp\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f1ae8f5-16c8-40a0-aa18-63b617df078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unit_test_stream(python, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(python)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1ddb38e-6b0a-4c37-baa4-ace0b7de887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", lines=10, value=python_hard)\n",
    "        cpp = gr.Textbox(label=\"Unit Test:\", lines=10)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "        convert = gr.Button(\"Create Unit Test code\")\n",
    "\n",
    "    convert.click(create_unit_test_stream, inputs=[python, model], outputs=[cpp])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19bf2bff-a822-4009-a539-f003b1651383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_python(code):\n",
    "    try:\n",
    "        output = io.StringIO()\n",
    "        sys.stdout = output\n",
    "        exec(code)\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a2274f1-d03b-42c0-8dcc-4ce159b18442",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".python {background-color: #306998;}\n",
    ".cpp {background-color: #050;}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1303932-160c-424b-97a8-d28c816721b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joeco\\AppData\\Local\\Temp\\ipykernel_53364\\1398746867.py\", line 5, in execute_python\n",
      "    exec(code)\n",
      "  File \"<string>\", line 83\n",
      "    - The above unit tests cover a variety of scenarios including basic small-sized arrays, larger arrays, and arrays with fixed range values.\n",
      "          ^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "E\n",
      "======================================================================\n",
      "ERROR: C:\\Users\\joeco\\AppData\\Roaming\\jupyter\\runtime\\kernel-164c650e-4184-44a0-bced-2c4612391c6d (unittest.loader._FailedTest.C:\\Users\\joeco\\AppData\\Roaming\\jupyter\\runtime\\kernel-164c650e-4184-44a0-bced-2c4612391c6d)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute 'C:\\Users\\joeco\\AppData\\Roaming\\jupyter\\runtime\\kernel-164c650e-4184-44a0-bced-2c4612391c6d'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.008s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\u001b[31mERROR\u001b[0m:    Traceback (most recent call last):\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joeco\\AppData\\Local\\Temp\\ipykernel_53364\\1398746867.py\", line 5, in execute_python\n",
      "    exec(code)\n",
      "  File \"<string>\", line 78, in <module>\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\unittest\\main.py\", line 102, in __init__\n",
      "    self.runTests()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\unittest\\main.py\", line 276, in runTests\n",
      "    sys.exit(not self.result.wasSuccessful())\n",
      "SystemExit: True\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 700, in lifespan\n",
      "    await receive()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\lifespan\\on.py\", line 137, in receive\n",
      "    return await self.receive_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\queues.py\", line 158, in get\n",
      "    await getter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joeco\\AppData\\Local\\Temp\\ipykernel_53364\\1398746867.py\", line 5, in execute_python\n",
      "    exec(code)\n",
      "  File \"<string>\", line 78, in <module>\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\unittest\\main.py\", line 102, in __init__\n",
      "    self.runTests()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\unittest\\main.py\", line 276, in runTests\n",
      "    sys.exit(not self.result.wasSuccessful())\n",
      "SystemExit: True\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 834, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\routing.py\", line 74, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 261, in __call__\n",
      "    async with anyio.create_task_group() as task_group:\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 776, in __aexit__\n",
      "    raise exc_val\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 268, in __call__\n",
      "    await wrap(partial(self.listen_for_disconnect, receive))\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 264, in wrap\n",
      "    await func()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\starlette\\responses.py\", line 233, in listen_for_disconnect\n",
      "    message = await receive()\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 563, in receive\n",
      "    await self.message_event.wait()\n",
      "  File \"D:\\Users\\joeco\\anaconda3\\envs\\llms\\Lib\\asyncio\\locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css=css) as ui:\n",
    "    gr.Markdown(\"## Test Python Code\")\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", value=python_hard, lines=10)\n",
    "        unitTest = gr.Textbox(label=\"Unit Test code:\", lines=10)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "    with gr.Row():\n",
    "        create_test = gr.Button(\"Create Unit tests code\")\n",
    "    with gr.Row():\n",
    "        python_run = gr.Button(\"Run Python\")\n",
    "        unit_test_run = gr.Button(\"Run Python Unit tests\")\n",
    "        # cpp_run = gr.Button(\"Run C++\")\n",
    "    with gr.Row():\n",
    "        python_out = gr.TextArea(label=\"Python result:\", elem_classes=[\"python\"])\n",
    "        unit_test_out = gr.TextArea(label=\"Unit Test result:\", elem_classes=[\"unitTest\"])\n",
    "\n",
    "    create_test.click(create_unit_test_stream, inputs=[python, model], outputs=[unitTest])\n",
    "    python_run.click(execute_python, inputs=[python], outputs=[python_out])\n",
    "    unit_test_run.click(execute_python, inputs=[unitTest], outputs=[unit_test_out])\n",
    "    # cpp_run.click(execute_cpp, inputs=[cpp], outputs=[cpp_out])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a6a97-5b8a-4a9b-8ee0-7561e0ced673",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Thank you to @CloudLlama for an amazing contribution</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                A student has contributed a chunk of code to improve this, in the next 2 cells. You can now select which Python porgram to run,\n",
    "                and a compiler is automatically selected that will work on PC, Windows and Mac. Massive thank you @CloudLlama!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ad093-425b-488e-8c3f-67f729dd9c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
